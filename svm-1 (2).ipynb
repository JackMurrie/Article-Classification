{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import model_selection, linear_model\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train_x = train[:9000]\n",
    "train_y = train['topic'][:9000]\n",
    "\n",
    "test_x = train[9000:]\n",
    "test_y = train['topic'][9000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for baseline model - 0.74\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "      ARTS CULTURE ENTERTAINMENT       0.29      0.50      0.36         4\n",
      "BIOGRAPHIES PERSONALITIES PEOPLE       0.44      0.57      0.50         7\n",
      "                         DEFENCE       0.45      0.50      0.48        10\n",
      "                DOMESTIC MARKETS       0.33      0.33      0.33         6\n",
      "                   FOREX MARKETS       0.35      0.37      0.36        41\n",
      "                          HEALTH       0.50      0.71      0.59         7\n",
      "                      IRRELEVANT       0.82      0.86      0.84       249\n",
      "                   MONEY MARKETS       0.68      0.53      0.60       101\n",
      "          SCIENCE AND TECHNOLOGY       1.00      0.67      0.80         3\n",
      "                  SHARE LISTINGS       0.71      0.71      0.71         7\n",
      "                          SPORTS       0.97      0.95      0.96        65\n",
      "\n",
      "                        accuracy                           0.74       500\n",
      "                       macro avg       0.59      0.61      0.59       500\n",
      "                    weighted avg       0.74      0.74      0.74       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_vec = CountVectorizer()\n",
    "count_vec.fit(train_x['article_words'])\n",
    "\n",
    "train_x_vec = count_vec.transform(train_x['article_words'])\n",
    "test_x_vec = count_vec.transform(test_x['article_words'])\n",
    "\n",
    "SVM = linear_model.SGDClassifier(loss=\"modified_huber\", shuffle=False)\n",
    "SVM.fit(train_x_vec, train_y)\n",
    "predictions_SVM = SVM.predict(test_x_vec)\n",
    "print(f'Accuracy for baseline model - {accuracy_score(predictions_SVM, test_y)}')\n",
    "print(classification_report(predictions_SVM, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(vectorizer=TfidfVectorizer(stop_words = 'english'), k='all', sampler=None, model=None):\n",
    "    \n",
    "    # Feature Extraction\n",
    "    vectorizer.fit(train_x['article_words'])\n",
    "    train_x_vec = vectorizer.transform(train_x['article_words'])\n",
    "    test_x_vec = vectorizer.transform(test_x['article_words'])\n",
    "    \n",
    "    # Feature Selection\n",
    "    feature_selector = SelectKBest(chi2, k=k)\n",
    "    feature_selector.fit(train_x_vec, train_y)\n",
    "    train_x_vec = feature_selector.transform(train_x_vec)\n",
    "    test_x_vec = feature_selector.transform(test_x_vec)\n",
    "    print(train_x_vec.shape)\n",
    "    \n",
    "    model = linear_model.SGDClassifier(loss=\"modified_huber\", shuffle=False)\n",
    "\n",
    "    # Sampling\n",
    "    if sampler:\n",
    "        train_x_res, train_y_res = sampler.fit_resample(train_x_vec, train_y)\n",
    "        print(train_x_res.shape)\n",
    "        model.fit(train_x_res, train_y_res)\n",
    "        predictions = model.predict(test_x_vec)\n",
    "        print(f'accuracy_score = {accuracy_score(predictions, test_y)}')\n",
    "\n",
    "    else:\n",
    "        model.fit(train_x_vec, train_y)\n",
    "        predictions = model.predict(test_x_vec)\n",
    "        print(f'accuracy_score = {accuracy_score(predictions, test_y)}')\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(9000, 34821)\n",
      "accuracy_score = 0.74\n",
      "\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 3), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(9000, 1012505)\n",
      "accuracy_score = 0.772\n",
      "\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(9000, 17812)\n",
      "accuracy_score = 0.734\n",
      "\n",
      "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
      "                ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n",
      "(9000, 194580)\n",
      "accuracy_score = 0.766\n",
      "\n",
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n",
      "(9000, 34724)\n",
      "accuracy_score = 0.786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorizers = [CountVectorizer(),\n",
    "               CountVectorizer(ngram_range=(1,3)),\n",
    "               CountVectorizer(min_df = 2),\n",
    "               CountVectorizer(stop_words=\"english\", ngram_range=(1,3), min_df = 2),\n",
    "               TfidfVectorizer(stop_words = 'english')\n",
    "              ]\n",
    "for v in vectorizers:\n",
    "    print(v)\n",
    "    test_model(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 100)\n",
      "accuracy_score = 0.734\n",
      "\n",
      "(9000, 1000)\n",
      "accuracy_score = 0.76\n",
      "\n",
      "(9000, 2500)\n",
      "accuracy_score = 0.774\n",
      "\n",
      "(9000, 5000)\n",
      "accuracy_score = 0.79\n",
      "\n",
      "(9000, 7500)\n",
      "accuracy_score = 0.784\n",
      "\n",
      "(9000, 10000)\n",
      "accuracy_score = 0.782\n",
      "\n",
      "(9000, 30000)\n",
      "accuracy_score = 0.786\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k_values = [100, 1000, 2500, 5000, 7500, 10000, 30000]\n",
    "\n",
    "for value in k_values:\n",
    "    test_model(k=value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomOverSampler(random_state=None, sampling_strategy='auto')\n",
      "(9000, 34724)\n",
      "(49203, 34724)\n",
      "accuracy_score = 0.642\n",
      "\n",
      "RandomUnderSampler(random_state=None, replacement=False,\n",
      "                   sampling_strategy='auto')\n",
      "(9000, 34724)\n",
      "(748, 34724)\n",
      "accuracy_score = 0.482\n",
      "\n",
      "SMOTE(k_neighbors=5, n_jobs=None, random_state=None, sampling_strategy='auto')\n",
      "(9000, 34724)\n",
      "(49203, 34724)\n",
      "accuracy_score = 0.656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samplers = [RandomOverSampler(), RandomUnderSampler(), SMOTE()]\n",
    "for s in samplers:\n",
    "    print(s)\n",
    "    test_model(sampler=s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.15, learning_rate='optimal', loss='modified_huber',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=False, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "SVM = linear_model.SGDClassifier(loss=\"modified_huber\", shuffle=False)\n",
    "\n",
    "# Best vectorizer and feature selection\n",
    "vectorizer=TfidfVectorizer(stop_words = 'english')\n",
    "k=5000\n",
    "\n",
    "# Feature Extraction\n",
    "vectorizer.fit(train_x['article_words'])\n",
    "train_x_vec = vectorizer.transform(train_x['article_words'])\n",
    "test_x_vec = vectorizer.transform(test_x['article_words'])\n",
    "\n",
    "# Feature Selection\n",
    "feature_selector = SelectKBest(chi2, k=k)\n",
    "feature_selector.fit(train_x_vec, train_y)\n",
    "train_x_vec = feature_selector.transform(train_x_vec)\n",
    "test_x_vec = feature_selector.transform(test_x_vec)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "parameters = [{'alpha': [0.0001, 0.01, 1, 100],'class_weight': [None, 'balanced']}]\n",
    "\n",
    "#gridsearch\n",
    "grid_search = model_selection.GridSearchCV(estimator = SVM, param_grid = parameters, scoring = 'accuracy', cv = 10)\n",
    "grid_search = grid_search.fit(train_x_vec, train_y)\n",
    "model = grid_search.best_estimator_\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score = 0.792\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "      ARTS CULTURE ENTERTAINMENT       0.43      0.75      0.55         4\n",
      "BIOGRAPHIES PERSONALITIES PEOPLE       0.44      0.50      0.47         8\n",
      "                         DEFENCE       0.64      0.50      0.56        14\n",
      "                DOMESTIC MARKETS       0.67      0.57      0.62         7\n",
      "                   FOREX MARKETS       0.58      0.43      0.50        58\n",
      "                          HEALTH       0.70      0.78      0.74         9\n",
      "                      IRRELEVANT       0.85      0.94      0.89       237\n",
      "                   MONEY MARKETS       0.66      0.62      0.64        85\n",
      "          SCIENCE AND TECHNOLOGY       1.00      0.67      0.80         3\n",
      "                  SHARE LISTINGS       0.86      0.67      0.75         9\n",
      "                          SPORTS       0.98      0.95      0.97        66\n",
      "\n",
      "                        accuracy                           0.79       500\n",
      "                       macro avg       0.71      0.67      0.68       500\n",
      "                    weighted avg       0.78      0.79      0.78       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x_vec, train_y)\n",
    "test_predictions_SVM = model.predict(test_x_vec)\n",
    "print(f'accuracy_score = {accuracy_score(test_predictions_SVM, test_y)}')\n",
    "print(classification_report(test_predictions_SVM, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggested Articles (for test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 5000)\n",
      "accuracy_score = 0.774\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "      ARTS CULTURE ENTERTAINMENT       0.00      0.00      0.00         6\n",
      "BIOGRAPHIES PERSONALITIES PEOPLE       0.00      0.00      0.00         6\n",
      "                         DEFENCE       0.00      0.00      0.00        17\n",
      "                DOMESTIC MARKETS       0.00      0.00      0.00         6\n",
      "                   FOREX MARKETS       0.07      0.06      0.07        48\n",
      "                          HEALTH       0.00      0.00      0.00        14\n",
      "                      IRRELEVANT       0.55      0.57      0.56       252\n",
      "                   MONEY MARKETS       0.17      0.17      0.17        81\n",
      "          SCIENCE AND TECHNOLOGY       0.50      0.50      0.50         2\n",
      "                  SHARE LISTINGS       0.00      0.00      0.00         6\n",
      "                          SPORTS       0.20      0.21      0.21        62\n",
      "\n",
      "                        accuracy                           0.35       500\n",
      "                       macro avg       0.14      0.14      0.14       500\n",
      "                    weighted avg       0.34      0.35      0.35       500\n",
      "\n",
      "\n",
      "Total classified articles as ARTS CULTURE ENTERTAINMENT = 4\n",
      "Suggested articles = [9604, 9895, 9878, 9767]\n",
      "\n",
      "Total classified articles as BIOGRAPHIES PERSONALITIES PEOPLE = 8\n",
      "Suggested articles = [9992, 9899, 9827, 9778, 9775, 9736, 9715, 9700]\n",
      "\n",
      "Total classified articles as DEFENCE = 14\n",
      "Suggested articles = [9968, 9964, 9849, 9768, 9711, 9683, 9678, 9669, 9653, 9594]\n",
      "\n",
      "Total classified articles as DOMESTIC MARKETS = 7\n",
      "Suggested articles = [9935, 9900, 9858, 9772, 9688, 9607, 9601]\n",
      "\n",
      "Total classified articles as FOREX MARKETS = 58\n",
      "Suggested articles = [9986, 9786, 9889, 9901, 9733, 9883, 9725, 9708, 9659, 9751]\n",
      "\n",
      "Total classified articles as HEALTH = 9\n",
      "Suggested articles = [9703, 9631, 9939, 9839, 9721, 9644, 9564, 9557, 9532]\n",
      "\n",
      "Total classified articles as IRRELEVANT = 237\n",
      "Suggested articles = [9976, 9971, 9950, 9914, 9913, 9912, 9909, 9907, 9906, 9897]\n",
      "\n",
      "Total classified articles as MONEY MARKETS = 85\n",
      "Suggested articles = [9755, 9583, 9835, 9820, 9720, 9840, 9650, 9737, 9961, 9776]\n",
      "\n",
      "Total classified articles as SCIENCE AND TECHNOLOGY = 3\n",
      "Suggested articles = [9982, 9917, 9534]\n",
      "\n",
      "Total classified articles as SHARE LISTINGS = 9\n",
      "Suggested articles = [9965, 9931, 9855, 9796, 9753, 9674, 9636, 9524, 9522]\n",
      "\n",
      "Total classified articles as SPORTS = 66\n",
      "Suggested articles = [9886, 9848, 9813, 9801, 9738, 9694, 9630, 9596, 9919, 9536]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get suggested articles\n",
    "\n",
    "final_test_x = vectorizer.transform(test['article_words'])\n",
    "final_test_x = feature_selector.transform(final_test_x)\n",
    "\n",
    "print(final_test_x.shape)\n",
    "\n",
    "final_test_y = test['topic']\n",
    "\n",
    "final_test_predictions = model.predict(final_test_x)\n",
    "print(f'accuracy_score = {accuracy_score(final_test_predictions, final_test_y)}')\n",
    "print(classification_report(final_test_predictions, test_y))\n",
    "print()\n",
    "\n",
    "test_probabilities_SVM = model.predict_proba(final_test_x)\n",
    "\n",
    "for i in range(len(model.classes_)):\n",
    "    topic = model.classes_[i]\n",
    "    article_indexes = range(len(test_predictions_SVM))\n",
    "    classified_articles = list(filter(lambda x: test_predictions_SVM[x] == topic, article_indexes))\n",
    "    articles_with_probabilities = list(map(lambda x: (test_probabilities_SVM[x][i], test['article_number'].values[x]), classified_articles))\n",
    "    suggested_articles = sorted(articles_with_probabilities, reverse=True)[:10]\n",
    "    \n",
    "    print(f'Total classified articles as {topic} = {len(classified_articles)}')   \n",
    "    print(f'Suggested articles = {[x[1] for x in suggested_articles]}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
