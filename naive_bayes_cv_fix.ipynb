{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes is a common method used in text classifiation and is one of the simplest and most practical learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_number                                      article_words  \\\n",
      "0               1  open,absent,cent,cent,cent,stock,inflow,rate,k...   \n",
      "1               2  morn,stead,end,end,day,day,day,patch,patch,pat...   \n",
      "2               3  socc,socc,world,world,recent,law,fifa,fifa,fif...   \n",
      "3               4  open,forint,forint,forint,forint,cent,cent,ste...   \n",
      "4               5  morn,complet,weekend,minut,minut,minut,arrow,d...   \n",
      "\n",
      "           topic  \n",
      "0  FOREX MARKETS  \n",
      "1  MONEY MARKETS  \n",
      "2         SPORTS  \n",
      "3  FOREX MARKETS  \n",
      "4     IRRELEVANT  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "data = pd.read_csv('training.csv')\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for base model: 0.732\n"
     ]
    }
   ],
   "source": [
    "#Count Vectorizer tokenizes and counts the word occurance for each document and builds a vocabulary of known words\n",
    "count = CountVectorizer()\n",
    "test_data = count.fit_transform(data[\"article_words\"])\n",
    "\n",
    "#Train / Development Split\n",
    "x_train = test_data[:9000]\n",
    "y_train = data[\"topic\"][:9000]\n",
    "\n",
    "x_dev = test_data[9000:]\n",
    "y_dev = data[\"topic\"][9000:]\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)\n",
    "y_pred = nb.predict(x_dev)\n",
    "\n",
    "print(\"Accuracy score for base model:\", accuracy_score(y_pred, y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  35822\n",
      "Accuracy score: 0.676\n",
      "Number of features:  35725\n",
      "Accuracy score: 0.736\n",
      "Number of features:  378659\n",
      "Accuracy score: 0.754\n",
      "Number of features:  18376\n",
      "Accuracy score: 0.73\n",
      "Number of features:  113355\n",
      "Accuracy score: 0.76\n"
     ]
    }
   ],
   "source": [
    "def feature_test(vector):\n",
    "    test_data = vector.fit_transform(data[\"article_words\"])\n",
    "\n",
    "    x_train = test_data[:9000]\n",
    "    y_train = data[\"topic\"][:9000]\n",
    "    x_dev = test_data[9000:]\n",
    "    y_dev = data[\"topic\"][9000:]\n",
    "\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(x_train, y_train)\n",
    "    y_pred = nb.predict(x_dev)\n",
    "    print(\"Number of features: \", x_train.shape[1])\n",
    "    print(\"Accuracy score:\", accuracy_score(y_pred, y_dev))\n",
    "\n",
    "#Some words will be very present (e.g. “the”, “a”, “is” in English) \n",
    "#hence carrying very little meaningful information about the actual contents of the document.\n",
    "#tf–idf transformation gives weight to words depeding on their frequency \n",
    "vector = TfidfVectorizer()\n",
    "feature_test(vector)\n",
    "\n",
    "#Stop words are words like “and”, “the”, “him”, which are presumed to be uninformative in representing the content of a text\n",
    "vector = CountVectorizer(stop_words=\"english\")\n",
    "feature_test(vector)\n",
    "\n",
    "#Unigrams and bigrams (groups of 2 words) can be used\n",
    "vector = CountVectorizer(ngram_range=(1,2))\n",
    "feature_test(vector)\n",
    "\n",
    "#min_df: ignore terms that have a document frequency strictly lower than the given threshold. Default 1\n",
    "vector = CountVectorizer(min_df = 2)\n",
    "feature_test(vector)\n",
    "\n",
    "#final chosen\n",
    "vector = CountVectorizer(stop_words=\"english\", ngram_range=(1,2), min_df = 2)\n",
    "feature_test(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score:  0.741111111111111\n",
      "Best parameters:  {'alpha': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'alpha': np.asarray(range(1,10,1))}\n",
    "grid = GridSearchCV(MultinomialNB(), param_grid, cv=5)\n",
    "grid.fit(x_train, y_train)\n",
    "print(\"Best cross-validation score: \", grid.best_score_)\n",
    "print(\"Best parameters: \", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results for Selected Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  113355\n",
      "Cross Val Scores:  [0.74105263 0.74157895 0.74052632 0.74368421 0.74894737]\n",
      "Accuracy: 0.74 (+/- 0.01)\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "      ARTS CULTURE ENTERTAINMENT       0.33      1.00      0.50         1\n",
      "BIOGRAPHIES PERSONALITIES PEOPLE       0.07      1.00      0.12         1\n",
      "                         DEFENCE       0.46      1.00      0.63         6\n",
      "                DOMESTIC MARKETS       0.00      0.00      0.00         0\n",
      "                   FOREX MARKETS       0.06      0.38      0.11         8\n",
      "                          HEALTH       0.36      0.83      0.50         6\n",
      "                      IRRELEVANT       0.84      0.81      0.83       276\n",
      "                   MONEY MARKETS       0.91      0.46      0.61       138\n",
      "          SCIENCE AND TECHNOLOGY       0.00      0.00      0.00         0\n",
      "                  SHARE LISTINGS       0.00      0.00      0.00         0\n",
      "                          SPORTS       1.00      0.94      0.97        64\n",
      "\n",
      "                        accuracy                           0.73       500\n",
      "                       macro avg       0.37      0.58      0.39       500\n",
      "                    weighted avg       0.86      0.73      0.76       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackc\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Chosen vectorizer \n",
    "vector = CountVectorizer(stop_words=\"english\", ngram_range=(1,2), min_df = 2)\n",
    "#Transform and fit training data\n",
    "x_train = vector.fit_transform(data[\"article_words\"])\n",
    "y_train = data[\"topic\"]\n",
    "\n",
    "#Build Final Model\n",
    "final_model = MultinomialNB(2)\n",
    "final_model.fit(x_train, y_train)\n",
    "\n",
    "#Import test data\n",
    "testdata = pd.read_csv('test.csv')\n",
    "#Transform test data\n",
    "x_test = vector.transform(testdata[\"article_words\"])\n",
    "y_test = testdata[\"topic\"]\n",
    "#Vocabulary size\n",
    "print(\"Number of features: \", x_test.shape[1])\n",
    "#Predict\n",
    "y_pred = final_model.predict(x_test)\n",
    "\n",
    "#Cross Validation Results\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(final_model, x_train, y_train, cv=5)\n",
    "print(\"Cross Val Scores: \", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "#Classification Report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that some classes are not being classified at all. They are instead being misclassified, this may be due to class imbalance. We fix this by oversampling the classes with fewer instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "      ARTS CULTURE ENTERTAINMENT       0.67      0.33      0.44         6\n",
      "BIOGRAPHIES PERSONALITIES PEOPLE       0.47      0.64      0.54        11\n",
      "                         DEFENCE       0.69      0.60      0.64        15\n",
      "                DOMESTIC MARKETS       0.50      0.14      0.22         7\n",
      "                   FOREX MARKETS       0.65      0.47      0.54        66\n",
      "                          HEALTH       0.64      0.64      0.64        14\n",
      "                      IRRELEVANT       0.73      0.90      0.81       216\n",
      "                   MONEY MARKETS       0.67      0.51      0.58        91\n",
      "          SCIENCE AND TECHNOLOGY       0.33      0.33      0.33         3\n",
      "                  SHARE LISTINGS       0.71      0.56      0.63         9\n",
      "                          SPORTS       0.98      0.95      0.97        62\n",
      "\n",
      "                        accuracy                           0.73       500\n",
      "                       macro avg       0.64      0.55      0.58       500\n",
      "                    weighted avg       0.72      0.73      0.72       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Oversample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "x_train, y_train = oversample.fit_resample(x_train, y_train)\n",
    "\n",
    "#Build Final Model\n",
    "final_model = MultinomialNB(2)\n",
    "final_model.fit(x_train, y_train)\n",
    "\n",
    "#Import test data\n",
    "testdata = pd.read_csv('test.csv')\n",
    "#Transform test data\n",
    "x_test = vector.transform(testdata[\"article_words\"])\n",
    "y_test = testdata[\"topic\"]\n",
    "#Predict\n",
    "y_pred = final_model.predict(x_test)\n",
    "\n",
    "#Classification Report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
